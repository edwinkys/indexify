{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install indexify indexify-extractor-sdk indexify-langchain langchain langchain-openai\n",
        "\n",
        "# Download Indexify Server\n",
        "!curl https://www.tensorlake.ai | sh\n",
        "\n",
        "# Install Poppler (required for PDF extraction)\n",
        "# You can use brew on MacOS.\n",
        "!sudo apt-get install -y poppler-utils\n",
        "\n",
        "# Download Extractors\n",
        "!indexify-extractor download hub://text/chunking\n",
        "!indexify-extractor download hub://embedding/minilm-l6\n",
        "!indexify-extractor download hub://pdf/pdf-extractor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After installing the necessary libraries, download the server, and the extractors, you need to restart the runtime. Then, you have to run Indexify Server with the Extractors.\n",
        "\n",
        "Open 2 terminals and run the following commands:\n",
        "\n",
        "```bash\n",
        "# Terminal 1\n",
        "./indexify server -d\n",
        "\n",
        "# Terminal 2\n",
        "indexify-extractor join-server\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Test the extractors**\n",
        "\n",
        "We will try PDFExtractor first. The PDFExtractor can extract all the values from text as well as tables in one shot and passes it to the next chained extractors which can be used for question answering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from indexify_extractor_sdk import load_extractor, Content\n",
        "\n",
        "pdfextractor, pdfconfig_cls = load_extractor(\"pdf-extractor.pdf_extractor:PDFExtractor\")\n",
        "content = Content.from_file(\"uber-20231231.pdf\")\n",
        "\n",
        "pdf_result = pdfextractor.extract(content)\n",
        "text_content = next(content.data.decode('utf-8') for content in pdf_result if content.content_type == 'text/plain')\n",
        "text_content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTIlKuPp6wxg"
      },
      "source": [
        "## **Create Extraction Graph**\n",
        "Instantiate the Indexify Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZNysNl-631k"
      },
      "outputs": [],
      "source": [
        "from indexify import IndexifyClient\n",
        "client = IndexifyClient()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQr1749x6_CW"
      },
      "source": [
        "### **Extraction Graph Setup**\n",
        "\n",
        "1. Import the `ExtractionGraph` class from the `indexify` package.\n",
        "\n",
        "2. Define the extraction graph specification in YAML format:\n",
        "   - Set the name of the extraction graph to \"pdfqa\".\n",
        "   - Define the extraction policies:\n",
        "     - Use the \"tensorlake/pdf-extractor\" extractor for PDF marking and name it \"pdf-extraction\".\n",
        "     - Use the \"tensorlake/chunk-extractor\" for text chunking and name it \"chunks\".\n",
        "       - Set the input parameters for the chunker:\n",
        "         - `chunk_size`: 1000 (size of each text chunk)\n",
        "         - `overlap`: 100 (overlap between chunks)\n",
        "         - `content_source`: \"pdf-extraction\" (source of content for chunking)\n",
        "     - Use the \"tensorlake/minilm-l6\" extractor for embedding and name it \"get-embeddings\".\n",
        "       - Set the content source for embedding to \"chunks\".\n",
        "\n",
        "3. Create an `ExtractionGraph` object from the YAML specification using `ExtractionGraph.from_yaml()`.\n",
        "\n",
        "4. Create the extraction graph on the Indexify client using `client.create_extraction_graph()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from indexify import ExtractionGraph\n",
        "\n",
        "extraction_graph_spec = \"\"\"\n",
        "name: 'pdf'\n",
        "extraction_policies:\n",
        "   - extractor: 'tensorlake/pdf-extractor'\n",
        "     name: 'pdf-extraction'\n",
        "   - extractor: 'tensorlake/chunk-extractor'\n",
        "     name: 'chunks'\n",
        "     input_params:\n",
        "        chunk_size: 1000\n",
        "        overlap: 100\n",
        "     content_source: 'pdf-extraction'\n",
        "   - extractor: 'tensorlake/minilm-l6'\n",
        "     name: 'get-embeddings'\n",
        "     content_source: 'chunks'\n",
        "\"\"\"\n",
        "\n",
        "extraction_graph = ExtractionGraph.from_yaml(extraction_graph_spec)\n",
        "client.create_extraction_graph(extraction_graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGqpkx3P7gsh"
      },
      "source": [
        "### **Upload a FORM 10-K PDF File**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eaw5wDEL79dy"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "req = requests.get(\"https://www.sec.gov/files/form10-k.pdf\")\n",
        "\n",
        "with open('form10-k.pdf','wb') as f:\n",
        "    f.write(req.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETideBqK8GGp"
      },
      "outputs": [],
      "source": [
        "content_id = client.upload_file(\"pdf\", path=\"form10-k.pdf\")\n",
        "client.wait_for_extraction(content_id)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2WDexIU8LFy"
      },
      "source": [
        "## **What is happening behind the scenes**\n",
        "\n",
        "Indexify is designed to seamlessly respond to ingestion events by assessing all existing policies and triggering the necessary extractors for extraction. Once the PDF extractor completes the process of extracting texts, bytes, and JSONs from the document, it automatically initiates the embedding extractor to chunk the content, extract embeddings, and populate an index.\n",
        "\n",
        "With Indexify, you have the ability to upload hundreds of PDF files simultaneously, and the platform will efficiently handle the extraction and indexing of the contents without requiring manual intervention. To expedite the extraction process, you can deploy multiple instances of the extractors, and Indexify's built-in scheduler will transparently distribute the workload among them, ensuring optimal performance and efficiency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6SQ0xDt9a_9"
      },
      "source": [
        "### **Perform RAG**\n",
        "Initialize the Langchain Retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2raD6aeB9Th1"
      },
      "outputs": [],
      "source": [
        "from indexify_langchain import IndexifyRetriever\n",
        "params = {\"name\": \"pdfqa.get-embeddings.embedding\", \"top_k\": 3}\n",
        "retriever = IndexifyRetriever(client=client, params=params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8Q1ulDM9u-e"
      },
      "source": [
        "Now create a chain to prompt OpenAI with data retrieved from Indexify to create a simple Q&A bot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FUO8cLA9unF"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfgv3imm9ZPG"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "model = ChatOpenAI()\n",
        "\n",
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckexWnEe-B3c"
      },
      "source": [
        "Now ask any question related to the ingested FORM 10-K PDF document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSc4uBLA-IEB"
      },
      "outputs": [],
      "source": [
        "chain.invoke(\"What are the disclosure with respect to Foreign Subsidiaries?\")\n",
        "# It may be omitted to the extent that the required disclosure would be detrimental to the registrant."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
